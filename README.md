<!-- Banner -->
<p align="center">
  <img src="https://github.com/sarthak576/InternsByte/blob/main/All%20documentation/images/demo.png" alt="Demo Banner" width="80%">
</p>

# ğŸ“š Developer Notes â€“ OpenAI, Whisper AI & More  

> ğŸš€ **Future-Proof & Clickable** â€“ This doc is structured for quick navigation, visual clarity, and easy updates.

---

## ğŸ“‘ Table of Contents
1. [ğŸ”‘ OpenAI API Key Usage](#-1-openai-api-key-usage)
2. [ğŸ™ï¸ Whisper AI â€“ Speech to Text](#-2-whisper-ai--speech-to-text)
3. [ğŸ“¦ Why Install `multipart`](#-3-why-install-multipart)
4. [ğŸ†• Using Latest OpenAI Version](#-4-using-latest-openai-version)
5. [âš¡ Quick Reference Table](#-quick-reference-table)

---

## ğŸ”‘ 1. OpenAI API Key Usage  

![Badge](https://img.shields.io/badge/Status-Important-red)  
### âœ… 5 Key Points â€“ Using `os.getenv("OPEN_AI_API_KEY")` for API Key:

1. **`os.getenv()` Reads Env Vars** â€“ Fetches `OPEN_AI_API_KEY` from environment variables.
2. **Must Export It ğŸ”** â€“ Before running:
   ```bash
   export OPEN_AI_API_KEY="your_api_key"



   ## ğŸ™ï¸ 2. Whisper AI â€“ Speech to Text  

![Badge](https://img.shields.io/badge/Model-Whisper_AI-blue)  
### âœ… 5 Key Points â€“ Using Whisper AI with ChatGPT/OpenAI:

1. **What is Whisper? ğŸ™ï¸** â€“ OpenAIâ€™s automatic speech recognition (ASR) model for converting audio to text.
2. **Usage in Code ğŸ’»**:
   ```python
   import openai

   openai.api_key = "your_api_key"

   audio_file = open("your_audio.mp3", "rb")
   transcript = openai.Audio.transcribe("whisper-1", audio_file)

   print(transcript["text"])

## ğŸ“¦ 3. Why Install `multipart`?  

![Badge](https://img.shields.io/badge/Package-python--multipart-green)  
### âœ… 2 Key Points â€“ `pip install multipart`:

1. **Purpose** â€“ Parses `multipart/form-data` for handling file uploads in FastAPI and similar frameworks.
2. **Example**:
   ```python
   from fastapi import FastAPI, File, UploadFile

   app = FastAPI()

   @app.post("/upload/")
   async def upload(file: UploadFile = File(...)):
       return {"filename": file.filename}

   
## ğŸ†• 4. Using Latest OpenAI Version  

![Badge](https://img.shields.io/badge/OpenAI-Version_1+-purple)  
### âœ… 5 Key Points â€“ Updating to Latest OpenAI SDK:

1. **API Key Change ğŸ”‘** â€“ Old: `openai.apikey` âŒ â†’ New: `OpenAI(api_key=...)` âœ…
2. **File Handling ğŸ“‚** â€“ Files are temporarily saved before being sent to the API.
3. **Method Update ğŸ› ï¸** â€“ Old: `transcribe()` âŒ â†’ New: `client.audio.transcriptions.create(...)` âœ…
4. **FastAPI Integration âš¡** â€“ `UploadFile = File(...)` ensures proper `multipart/form-data` handling.
5. **Future-Proofing ğŸš€** â€“ v1+ syntax prevents deprecation issues and keeps code up-to-date.


## âš¡ 5. Quick Reference Table  

![Badge](https://img.shields.io/badge/Reference-Quick_Access-orange)  

| Section | Topic | Key Command / Code | Notes |
|---------|-------|-------------------|-------|
| 1 | OpenAI API Key Usage | `export OPEN_AI_API_KEY="your_api_key"` | Set in terminal before running app |
| 2 | Whisper AI â€“ Speech to Text | `openai.Audio.transcribe("whisper-1", audio_file)` | Works with `.mp3`, `.wav`, `.m4a`, etc. |
| 3 | Install `multipart` | `pip install python-multipart` | Needed for file uploads in FastAPI |
| 4 | Latest OpenAI Version | `OpenAI(api_key=...)` & `client.audio.transcriptions.create(...)` | Updated v1+ SDK syntax |

